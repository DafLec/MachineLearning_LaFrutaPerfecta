{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYoali Sotomayor Baqueiro  A01650536\\nDavid Radames Gómez Chiu  A01334574\\nDafne Lecona Cisneros     A01334365\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Yoali Sotomayor Baqueiro  A01650536\n",
    "David Radames Gómez Chiu  A01334574\n",
    "Dafne Lecona Cisneros     A01334365\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "import pickle\n",
    "import keras.models\n",
    "#import skimage.io\n",
    "import random\n",
    "import cv2\n",
    "#from tqmd import tqmd\n",
    "DIRECTORY = \"img\"\n",
    "FRUITS = [\"bananas\"]\n",
    "CATEGORIES = [\"good\", \"black\",\"green\"]\n",
    "IMG_SIZE = 72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Falta cargar/crear una base de datos. sólo copié lo del profe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not enough values to unpack (expected 3, got 0)\n",
      "not enough values to unpack (expected 3, got 0)\n",
      "not enough values to unpack (expected 3, got 0)\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "for fruit in FRUITS:\n",
    "    for cat in CATEGORIES:\n",
    "        path = os.path.join(DIRECTORY,fruit,cat)\n",
    "        class_num = CATEGORIES.index(cat) #good = 0  | bad = 1, black = 1 | green = 2\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                \n",
    "                img_array = cv2.imread(os.path.join(path,img))\n",
    "                b,g,r = cv2.split(img_array)\n",
    "                new_array = cv2.merge([r,g,b])\n",
    "                new_array = cv2.resize(new_array, (IMG_SIZE, IMG_SIZE))\n",
    "                #plt.subplot(122)\n",
    "                #plt.imshow(new_array)\n",
    "                images.append([new_array, class_num])\n",
    "                \n",
    "                #plt.imshow(new_array, cmap='gray')  # Graficar un imagen\n",
    "                #plt.show()  # Mostrar\n",
    "\n",
    "            except Exception as e:\n",
    "                print(str(e))\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imágenes a matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "random.shuffle(images)\n",
    "for i, clase in images:\n",
    "    X.append(i)\n",
    "    y.append(clase)\n",
    "    \n",
    "salida = open(\"X.pickel\",\"wb\")\n",
    "pickle.dump(X, salida)\n",
    "salida.close()\n",
    "salida = open(\"y.pickel\",\"wb\")\n",
    "pickle.dump(y, salida)\n",
    "salida.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X = X/X.max() ##NO CORRER MÁS DE UNA VEZ\n",
    "X = X.reshape(-1,72,72,3)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = Sequential()\n",
    "\n",
    "modelo.add(Conv2D(32,(3,3),padding=\"valid\",input_shape=X.shape[1:]))\n",
    "modelo.add(Activation('relu'))\n",
    "modelo.add(MaxPooling2D(pool_size=(3,3)))\n",
    "modelo.add(Conv2D(32,(3,3),input_shape=X.shape[1:]))\n",
    "modelo.add(Activation('relu'))\n",
    "modelo.add(MaxPooling2D(pool_size=(2,2)))\n",
    "modelo.add(Flatten())\n",
    "modelo.add(Dense(10,activation='relu'))\n",
    "modelo.add(Dense(15,activation='relu'))\n",
    "modelo.add(Dense(10,activation='relu'))\n",
    "modelo.add(Dense(3,activation='relu'))\n",
    "modelo.add(Dense(3))\n",
    "modelo.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1074 samples, validate on 359 samples\n",
      "Epoch 1/30\n",
      "1074/1074 [==============================] - 4s 3ms/step - loss: 1.0540 - acc: 0.4385 - val_loss: 0.9545 - val_acc: 0.7019\n",
      "Epoch 2/30\n",
      "1074/1074 [==============================] - 3s 3ms/step - loss: 0.7379 - acc: 0.7588 - val_loss: 0.5622 - val_acc: 0.7465\n",
      "Epoch 3/30\n",
      "1074/1074 [==============================] - 3s 3ms/step - loss: 0.4097 - acc: 0.9069 - val_loss: 0.2738 - val_acc: 0.9916\n",
      "Epoch 4/30\n",
      "1074/1074 [==============================] - 3s 3ms/step - loss: 0.2214 - acc: 0.9609 - val_loss: 0.1362 - val_acc: 0.9666\n",
      "Epoch 5/30\n",
      "1074/1074 [==============================] - 3s 3ms/step - loss: 0.1434 - acc: 0.9693 - val_loss: 0.0521 - val_acc: 0.9972\n",
      "Epoch 6/30\n",
      "1074/1074 [==============================] - 3s 3ms/step - loss: 0.0717 - acc: 0.9870 - val_loss: 0.0373 - val_acc: 1.0000\n",
      "Epoch 7/30\n",
      "1074/1074 [==============================] - 3s 3ms/step - loss: 0.0626 - acc: 0.9842 - val_loss: 0.0230 - val_acc: 1.0000\n",
      "Epoch 8/30\n",
      "1074/1074 [==============================] - 3s 3ms/step - loss: 0.0415 - acc: 0.9898 - val_loss: 0.0364 - val_acc: 0.9944\n",
      "Epoch 9/30\n",
      "1074/1074 [==============================] - 3s 3ms/step - loss: 0.0259 - acc: 0.9926 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 10/30\n",
      "1074/1074 [==============================] - 3s 3ms/step - loss: 0.0267 - acc: 0.9935 - val_loss: 0.0655 - val_acc: 0.9833\n",
      "Epoch 11/30\n",
      "1074/1074 [==============================] - 3s 3ms/step - loss: 0.0342 - acc: 0.9926 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 12/30\n",
      "1074/1074 [==============================] - 3s 3ms/step - loss: 0.0085 - acc: 0.9991 - val_loss: 0.0120 - val_acc: 1.0000\n",
      "Epoch 13/30\n",
      "1074/1074 [==============================] - 3s 3ms/step - loss: 0.0101 - acc: 0.9972 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 14/30\n",
      "1074/1074 [==============================] - 4s 3ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 15/30\n",
      "1056/1074 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9991"
     ]
    }
   ],
   "source": [
    "modelo.compile(optimizer = 'adam', loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
    "X2 = np.array(X,dtype='float32')\n",
    "modelo.fit(X2,to_categorical(y),batch_size=32, epochs=30, validation_split=.25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carga(rutaImg):\n",
    "    imgSize = 72\n",
    "    imgArray = cv2.imread(os.path.join(path,img))\n",
    "    b,g,r = cv2.split(img_array)\n",
    "    nImgArray = cv2.merge([r,g,b])\n",
    "    nImgArray = cv2.resize(new_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return nImgArray.reshape(-1, imgSize, imgSize, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.save(\"modelo.model\")\n",
    "modelo = keras.models.load_model('modelo.model')\n",
    "nombre = input(\"imagen? \")\n",
    "p = modelo.predict([carga(nombre)])\n",
    "print(\"p:\",p)\n",
    "indice = np.argmax(p[0])\n",
    "print(CATEGORIES[indice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
