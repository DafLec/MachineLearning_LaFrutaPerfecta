{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYoali Sotomayor Baqueiro  A01650536\\nDavid Radames Gómez Chiu  A01334574\\nDafne Lecona Cisneros     A01334365\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Yoali Sotomayor Baqueiro  A01650536\n",
    "David Radames Gómez Chiu  A01334574\n",
    "Dafne Lecona Cisneros     A01334365\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "import pickle\n",
    "import keras.models\n",
    "#import skimage.io\n",
    "import random\n",
    "import cv2\n",
    "#from tqmd import tqmd\n",
    "DIRECTORY = \"img\"\n",
    "FRUITS = [\"bananas\"]\n",
    "CATEGORIES = [\"good\", \"black\",\"green\"]\n",
    "IMG_SIZE = 72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Falta cargar/crear una base de datos. sólo copié lo del profe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not enough values to unpack (expected 3, got 0)\n",
      "not enough values to unpack (expected 3, got 0)\n",
      "not enough values to unpack (expected 3, got 0)\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "for fruit in FRUITS:\n",
    "    for cat in CATEGORIES:\n",
    "        path = os.path.join(DIRECTORY,fruit,cat)\n",
    "        class_num = CATEGORIES.index(cat) #good = 0  | bad = 1, black = 1 | green = 2\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                \n",
    "                img_array = cv2.imread(os.path.join(path,img))\n",
    "                b,g,r = cv2.split(img_array)\n",
    "                new_array = cv2.merge([r,g,b])\n",
    "                new_array = cv2.resize(new_array, (IMG_SIZE, IMG_SIZE))\n",
    "                #plt.subplot(122)\n",
    "                #plt.imshow(new_array)\n",
    "                images.append([new_array, class_num])\n",
    "                \n",
    "                #plt.imshow(new_array, cmap='gray')  # Graficar un imagen\n",
    "                #plt.show()  # Mostrar\n",
    "\n",
    "            except Exception as e:\n",
    "                print(str(e))\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imágenes a matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "random.shuffle(images)\n",
    "for i, clase in images:\n",
    "    X.append(i)\n",
    "    y.append(clase)\n",
    "    \n",
    "salida = open(\"X.pickel\",\"wb\")\n",
    "pickle.dump(X, salida)\n",
    "salida.close()\n",
    "salida = open(\"y.pickel\",\"wb\")\n",
    "pickle.dump(y, salida)\n",
    "salida.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X = X/X.max() ##NO CORRER MÁS DE UNA VEZ\n",
    "X = X.reshape(-1,72,72,3)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modelo = Sequential()\n",
    "\n",
    "modelo.add(Conv2D(32,(3,3),padding=\"valid\",input_shape=X.shape[1:]))\n",
    "modelo.add(Activation('relu'))\n",
    "modelo.add(MaxPooling2D(pool_size=(3,3)))\n",
    "modelo.add(Conv2D(32,(3,3),input_shape=X.shape[1:]))\n",
    "modelo.add(Activation('relu'))\n",
    "modelo.add(MaxPooling2D(pool_size=(2,2)))\n",
    "modelo.add(Flatten())\n",
    "modelo.add(Dense(10,activation='relu'))\n",
    "modelo.add(Dense(15,activation='relu'))\n",
    "modelo.add(Dense(10,activation='relu'))\n",
    "modelo.add(Dense(3,activation='relu'))\n",
    "modelo.add(Dense(3,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = Sequential()\n",
    "\n",
    "modelo.add(Conv2D(32,(7,7),input_shape=X.shape[1:]))\n",
    "modelo.add(Activation('relu'))\n",
    "modelo.add(MaxPooling2D(pool_size=(2,2)))\n",
    "modelo.add(Conv2D(64,(5,5),input_shape=X.shape[1:]))\n",
    "modelo.add(Activation('relu'))\n",
    "modelo.add(MaxPooling2D(pool_size=(2,2)))\n",
    "modelo.add(Conv2D(128,(3,3),input_shape=X.shape[1:]))\n",
    "modelo.add(Activation('relu'))\n",
    "modelo.add(MaxPooling2D(pool_size=(2,2)))\n",
    "modelo.add(Flatten())\n",
    "modelo.add(Dense(128,activation='relu'))\n",
    "modelo.add(Dense(3,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1785 samples, validate on 595 samples\n",
      "Epoch 1/30\n",
      "1785/1785 [==============================] - 20s 11ms/step - loss: 0.9823 - categorical_accuracy: 0.5154 - val_loss: 0.7828 - val_categorical_accuracy: 0.7950\n",
      "Epoch 2/30\n",
      "1785/1785 [==============================] - 20s 11ms/step - loss: 0.6744 - categorical_accuracy: 0.7333 - val_loss: 0.3921 - val_categorical_accuracy: 0.7950\n",
      "Epoch 3/30\n",
      "1785/1785 [==============================] - 20s 11ms/step - loss: 0.6411 - categorical_accuracy: 0.8151 - val_loss: 0.3292 - val_categorical_accuracy: 0.8454\n",
      "Epoch 4/30\n",
      "1785/1785 [==============================] - 20s 11ms/step - loss: 0.2573 - categorical_accuracy: 0.8992 - val_loss: 0.1414 - val_categorical_accuracy: 0.9731\n",
      "Epoch 5/30\n",
      "1785/1785 [==============================] - 19s 11ms/step - loss: 0.2406 - categorical_accuracy: 0.9188 - val_loss: 0.1666 - val_categorical_accuracy: 0.9311\n",
      "Epoch 6/30\n",
      "1785/1785 [==============================] - 19s 11ms/step - loss: 0.1193 - categorical_accuracy: 0.9585 - val_loss: 0.4616 - val_categorical_accuracy: 0.8353\n",
      "Epoch 7/30\n",
      "1785/1785 [==============================] - 18s 10ms/step - loss: 0.2575 - categorical_accuracy: 0.9300 - val_loss: 0.0529 - val_categorical_accuracy: 0.9866\n",
      "Epoch 8/30\n",
      "1785/1785 [==============================] - 18s 10ms/step - loss: 0.1359 - categorical_accuracy: 0.9563 - val_loss: 0.0476 - val_categorical_accuracy: 0.9916\n",
      "Epoch 9/30\n",
      "1785/1785 [==============================] - 19s 10ms/step - loss: 0.0310 - categorical_accuracy: 0.9933 - val_loss: 0.0392 - val_categorical_accuracy: 0.9916\n",
      "Epoch 10/30\n",
      "1785/1785 [==============================] - 19s 10ms/step - loss: 0.1201 - categorical_accuracy: 0.9703 - val_loss: 0.0672 - val_categorical_accuracy: 0.9916\n",
      "Epoch 11/30\n",
      "1785/1785 [==============================] - 19s 10ms/step - loss: 0.0292 - categorical_accuracy: 0.9938 - val_loss: 0.0420 - val_categorical_accuracy: 0.9916\n",
      "Epoch 12/30\n",
      "1785/1785 [==============================] - 19s 10ms/step - loss: 0.0276 - categorical_accuracy: 0.9922 - val_loss: 0.7154 - val_categorical_accuracy: 0.7496\n",
      "Epoch 13/30\n",
      "1785/1785 [==============================] - 19s 10ms/step - loss: 0.1340 - categorical_accuracy: 0.9636 - val_loss: 0.0451 - val_categorical_accuracy: 0.9899\n",
      "Epoch 14/30\n",
      "1785/1785 [==============================] - 19s 10ms/step - loss: 0.0191 - categorical_accuracy: 0.9955 - val_loss: 0.0456 - val_categorical_accuracy: 0.9866\n",
      "Epoch 15/30\n",
      "1785/1785 [==============================] - 18s 10ms/step - loss: 0.0178 - categorical_accuracy: 0.9955 - val_loss: 0.0463 - val_categorical_accuracy: 0.9866\n",
      "Epoch 16/30\n",
      "1785/1785 [==============================] - 19s 10ms/step - loss: 0.0188 - categorical_accuracy: 0.9933 - val_loss: 0.0264 - val_categorical_accuracy: 0.9899\n",
      "Epoch 17/30\n",
      "1785/1785 [==============================] - 19s 10ms/step - loss: 0.0128 - categorical_accuracy: 0.9961 - val_loss: 0.0342 - val_categorical_accuracy: 0.9916\n",
      "Epoch 18/30\n",
      "1785/1785 [==============================] - 19s 10ms/step - loss: 0.0147 - categorical_accuracy: 0.9961 - val_loss: 0.0294 - val_categorical_accuracy: 0.9916\n",
      "Epoch 19/30\n",
      "1785/1785 [==============================] - 19s 10ms/step - loss: 0.0157 - categorical_accuracy: 0.9955 - val_loss: 0.0221 - val_categorical_accuracy: 0.9933\n",
      "Epoch 20/30\n",
      "1785/1785 [==============================] - 18s 10ms/step - loss: 0.0123 - categorical_accuracy: 0.9961 - val_loss: 0.0249 - val_categorical_accuracy: 0.9916\n",
      "Epoch 21/30\n",
      "1785/1785 [==============================] - 19s 10ms/step - loss: 0.1523 - categorical_accuracy: 0.9569 - val_loss: 0.0681 - val_categorical_accuracy: 0.9916\n",
      "Epoch 22/30\n",
      "1785/1785 [==============================] - 19s 10ms/step - loss: 0.0201 - categorical_accuracy: 0.9978 - val_loss: 0.0393 - val_categorical_accuracy: 0.9882\n",
      "Epoch 23/30\n",
      "1785/1785 [==============================] - 19s 11ms/step - loss: 0.0161 - categorical_accuracy: 0.9944 - val_loss: 0.0239 - val_categorical_accuracy: 0.9916\n",
      "Epoch 24/30\n",
      "1785/1785 [==============================] - 19s 10ms/step - loss: 0.0506 - categorical_accuracy: 0.9894 - val_loss: 0.0240 - val_categorical_accuracy: 0.9916\n",
      "Epoch 25/30\n",
      "1785/1785 [==============================] - 19s 11ms/step - loss: 0.0103 - categorical_accuracy: 0.9978 - val_loss: 0.0185 - val_categorical_accuracy: 0.9950\n",
      "Epoch 26/30\n",
      "1785/1785 [==============================] - 19s 10ms/step - loss: 0.0086 - categorical_accuracy: 0.9978 - val_loss: 0.0270 - val_categorical_accuracy: 0.9916\n",
      "Epoch 27/30\n",
      "1785/1785 [==============================] - 19s 10ms/step - loss: 0.0068 - categorical_accuracy: 0.9983 - val_loss: 0.0180 - val_categorical_accuracy: 0.9933\n",
      "Epoch 28/30\n",
      "1785/1785 [==============================] - 19s 10ms/step - loss: 0.0067 - categorical_accuracy: 0.9983 - val_loss: 0.0198 - val_categorical_accuracy: 0.9916\n",
      "Epoch 29/30\n",
      "1785/1785 [==============================] - 19s 11ms/step - loss: 0.0064 - categorical_accuracy: 0.9983 - val_loss: 0.0145 - val_categorical_accuracy: 0.9950\n",
      "Epoch 30/30\n",
      "1785/1785 [==============================] - 19s 11ms/step - loss: 0.0046 - categorical_accuracy: 0.9989 - val_loss: 0.0233 - val_categorical_accuracy: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb1dd92fd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.compile(optimizer = 'SGD', loss = 'categorical_crossentropy',metrics=['categorical_accuracy'])\n",
    "X2 = np.array(X,dtype='float32')\n",
    "modelo.fit(X2,to_categorical(y),batch_size=32, epochs=30, validation_split=.25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carga(rutaImg):\n",
    "    imgSize = 72\n",
    "    imgArray = cv2.imread(os.path.join(path,img))\n",
    "    b,g,r = cv2.split(img_array)\n",
    "    nImgArray = cv2.merge([r,g,b])\n",
    "    nImgArray = cv2.resize(new_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return nImgArray.reshape(-1, imgSize, imgSize, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagen? verde.jpeg\n",
      "p: [[0. 0. 1.]]\n",
      "green\n"
     ]
    }
   ],
   "source": [
    "modelo.save(\"modelo.model\")\n",
    "modelo = keras.models.load_model('modelo.model')\n",
    "nombre = input(\"imagen? \")\n",
    "p = modelo.predict([carga(nombre)])\n",
    "print(\"p:\",p)\n",
    "indice = np.argmax(p[0])\n",
    "print(CATEGORIES[indice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
