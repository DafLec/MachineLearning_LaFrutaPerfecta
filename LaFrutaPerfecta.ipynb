{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Yoali Sotomayor Baqueiro  A01650536\n",
    "David Radames Gómez Chiu  A01334574\n",
    "Dafne Lecona Cisneros     A01334365\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "import keras.models\n",
    "#import skimage.io\n",
    "import random\n",
    "import cv2\n",
    "#from tqmd import tqmd\n",
    "DIRECTORY = \"img\"\n",
    "FRUITS = [\"bananas\"]\n",
    "CATEGORIES = [\"good\", \"bad\"]\n",
    "IMG_SIZE = 72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Falta cargar/crear una base de datos. sólo copié lo del profe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not enough values to unpack (expected 3, got 0)\n",
      "not enough values to unpack (expected 3, got 0)\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "for fruit in FRUITS:\n",
    "    for cat in CATEGORIES:\n",
    "        path = os.path.join(DIRECTORY,fruit,cat)\n",
    "        class_num = CATEGORIES.index(cat) #good = 0  | bad = 1\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                \n",
    "                img_array = cv2.imread(os.path.join(path,img))\n",
    "                b,g,r = cv2.split(img_array)\n",
    "                new_array = cv2.merge([r,g,b])\n",
    "                new_array = cv2.resize(new_array, (IMG_SIZE, IMG_SIZE))\n",
    "                #plt.subplot(122)\n",
    "                #plt.imshow(new_array)\n",
    "                images.append([new_array, class_num])\n",
    "                #plt.imshow(new_array, cmap='gray')  # Graficar un imagen\n",
    "                #plt.show()  # Mostrar\n",
    "\n",
    "            except Exception as e:\n",
    "                print(str(e))\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imágenes a matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "random.shuffle(images)\n",
    "for i, clase in images:\n",
    "    X.append(i)\n",
    "    y.append(clase)\n",
    "    \n",
    "salida = open(\"X.pickel\",\"wb\")\n",
    "pickle.dump(X, salida)\n",
    "salida.close()\n",
    "salida = open(\"y.pickel\",\"wb\")\n",
    "pickle.dump(y, salida)\n",
    "salida.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X = X/X.max() ##NO CORRER MÁS DE UNA VEZ\n",
    "X = X.reshape(-1,72,72,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = Sequential()\n",
    "\n",
    "modelo.add(Conv2D(32,(3,3),input_shape=X.shape[1:]))\n",
    "modelo.add(Activation('relu'))\n",
    "modelo.add(MaxPooling2D(pool_size=(2,2)))\n",
    "modelo.add(Conv2D(32,(3,3),input_shape=X.shape[1:]))\n",
    "modelo.add(Activation('relu'))\n",
    "modelo.add(MaxPooling2D(pool_size=(2,2)))\n",
    "modelo.add(Flatten())\n",
    "modelo.add(Dense(1))\n",
    "modelo.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 515 samples, validate on 172 samples\n",
      "Epoch 1/30\n",
      "515/515 [==============================] - 4s 8ms/step - loss: 0.6483 - acc: 0.6311 - val_loss: 0.6691 - val_acc: 0.6047\n",
      "Epoch 2/30\n",
      "515/515 [==============================] - 5s 11ms/step - loss: 0.5506 - acc: 0.7049 - val_loss: 0.6246 - val_acc: 0.6512\n",
      "Epoch 3/30\n",
      "515/515 [==============================] - 6s 12ms/step - loss: 0.5142 - acc: 0.7359 - val_loss: 0.5467 - val_acc: 0.6919\n",
      "Epoch 4/30\n",
      "515/515 [==============================] - 5s 9ms/step - loss: 0.4689 - acc: 0.7650 - val_loss: 0.5080 - val_acc: 0.7267\n",
      "Epoch 5/30\n",
      "515/515 [==============================] - 5s 9ms/step - loss: 0.4357 - acc: 0.7961 - val_loss: 0.4858 - val_acc: 0.7326\n",
      "Epoch 6/30\n",
      "515/515 [==============================] - 5s 9ms/step - loss: 0.3965 - acc: 0.8097 - val_loss: 0.6294 - val_acc: 0.6802\n",
      "Epoch 7/30\n",
      "515/515 [==============================] - 4s 8ms/step - loss: 0.3735 - acc: 0.8252 - val_loss: 0.4469 - val_acc: 0.8081\n",
      "Epoch 8/30\n",
      "515/515 [==============================] - 4s 8ms/step - loss: 0.3537 - acc: 0.8194 - val_loss: 0.4452 - val_acc: 0.7733\n",
      "Epoch 9/30\n",
      "515/515 [==============================] - 4s 8ms/step - loss: 0.3061 - acc: 0.8583 - val_loss: 0.6746 - val_acc: 0.7093\n",
      "Epoch 10/30\n",
      "515/515 [==============================] - 4s 9ms/step - loss: 0.3192 - acc: 0.8641 - val_loss: 0.4657 - val_acc: 0.7733\n",
      "Epoch 11/30\n",
      "515/515 [==============================] - 4s 8ms/step - loss: 0.2767 - acc: 0.8816 - val_loss: 0.6641 - val_acc: 0.7035\n",
      "Epoch 12/30\n",
      "515/515 [==============================] - 4s 8ms/step - loss: 0.2944 - acc: 0.8699 - val_loss: 0.4549 - val_acc: 0.7616\n",
      "Epoch 13/30\n",
      "515/515 [==============================] - 4s 8ms/step - loss: 0.2837 - acc: 0.8913 - val_loss: 0.5515 - val_acc: 0.7384\n",
      "Epoch 14/30\n",
      "515/515 [==============================] - 4s 8ms/step - loss: 0.2663 - acc: 0.8854 - val_loss: 0.5776 - val_acc: 0.7267\n",
      "Epoch 15/30\n",
      "515/515 [==============================] - 4s 8ms/step - loss: 0.2445 - acc: 0.8932 - val_loss: 0.5075 - val_acc: 0.7384\n",
      "Epoch 16/30\n",
      "515/515 [==============================] - 5s 9ms/step - loss: 0.2354 - acc: 0.9049 - val_loss: 0.4512 - val_acc: 0.7907\n",
      "Epoch 17/30\n",
      "515/515 [==============================] - 5s 9ms/step - loss: 0.2259 - acc: 0.9107 - val_loss: 0.5095 - val_acc: 0.7384\n",
      "Epoch 18/30\n",
      "515/515 [==============================] - 4s 8ms/step - loss: 0.2303 - acc: 0.8971 - val_loss: 0.4487 - val_acc: 0.7733\n",
      "Epoch 19/30\n",
      "515/515 [==============================] - 4s 8ms/step - loss: 0.2001 - acc: 0.9126 - val_loss: 0.6014 - val_acc: 0.7267\n",
      "Epoch 20/30\n",
      "515/515 [==============================] - 5s 10ms/step - loss: 0.2195 - acc: 0.8874 - val_loss: 0.4518 - val_acc: 0.8198\n",
      "Epoch 21/30\n",
      "515/515 [==============================] - 5s 9ms/step - loss: 0.1917 - acc: 0.9029 - val_loss: 0.4800 - val_acc: 0.7500\n",
      "Epoch 22/30\n",
      "515/515 [==============================] - 5s 10ms/step - loss: 0.1694 - acc: 0.9262 - val_loss: 0.6468 - val_acc: 0.7442\n",
      "Epoch 23/30\n",
      "515/515 [==============================] - 5s 10ms/step - loss: 0.1738 - acc: 0.9262 - val_loss: 0.4774 - val_acc: 0.7384\n",
      "Epoch 24/30\n",
      "515/515 [==============================] - 6s 11ms/step - loss: 0.1477 - acc: 0.9437 - val_loss: 0.4857 - val_acc: 0.7500\n",
      "Epoch 25/30\n",
      "515/515 [==============================] - 6s 12ms/step - loss: 0.1375 - acc: 0.9476 - val_loss: 0.4772 - val_acc: 0.7733\n",
      "Epoch 26/30\n",
      "515/515 [==============================] - 7s 13ms/step - loss: 0.1358 - acc: 0.9437 - val_loss: 0.5846 - val_acc: 0.7500\n",
      "Epoch 27/30\n",
      "515/515 [==============================] - 7s 14ms/step - loss: 0.1477 - acc: 0.9282 - val_loss: 0.4743 - val_acc: 0.7616\n",
      "Epoch 28/30\n",
      "515/515 [==============================] - 5s 10ms/step - loss: 0.1269 - acc: 0.9631 - val_loss: 0.5000 - val_acc: 0.7442\n",
      "Epoch 29/30\n",
      "515/515 [==============================] - 6s 12ms/step - loss: 0.1043 - acc: 0.9709 - val_loss: 0.5641 - val_acc: 0.7558\n",
      "Epoch 30/30\n",
      "515/515 [==============================] - 6s 11ms/step - loss: 0.1073 - acc: 0.9553 - val_loss: 0.4881 - val_acc: 0.7849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20fa39b88d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics=['accuracy'])\n",
    "X2 = np.array(X,dtype='float32')\n",
    "modelo.fit(X2,y,batch_size=32, epochs=30, validation_split=.25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carga(rutaImg):\n",
    "    imgSize = 72\n",
    "    imgArray = cv2.imread(os.path.join(path,img))\n",
    "    b,g,r = cv2.split(img_array)\n",
    "    nImgArray = cv2.merge([r,g,b])\n",
    "    nImgArray = cv2.resize(new_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return nImgArray.reshape(-1, imgSize, imgSize, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagen? good.jpg\n",
      "[[0.]]\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "modelo.save(\"modelo.model\")\n",
    "modelo = keras.models.load_model('modelo.model')\n",
    "nombre = input(\"imagen? \")\n",
    "p = modelo.predict([carga(nombre)])\n",
    "print(p)\n",
    "print(CATEGORIES[   int(p[0][0])  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
